.. _dictionary:

Словари
=======

В pymorphy2 используются словари из проекта OpenCorpora_,
специальным образом обработанные для быстрых выборок.

.. _OpenCorpora: http://opencorpora.org

Упаковка словаря
----------------

Исходный словарь из OpenCorpora_ представляет собой текстовый файл,
в котором слова объединены в "леммы" следующим образом::

    1
    ЁЖ      NOUN,anim,masc sing,nomn
    ЕЖА     NOUN,anim,masc sing,gent
    ЕЖУ     NOUN,anim,masc sing,datv
    ЕЖА     NOUN,anim,masc sing,accs
    ЕЖОМ    NOUN,anim,masc sing,ablt
    ЕЖЕ     NOUN,anim,masc sing,loct
    ЕЖИ     NOUN,anim,masc plur,nomn
    ЕЖЕЙ    NOUN,anim,masc plur,gent
    ЕЖАМ    NOUN,anim,masc plur,datv
    ЕЖЕЙ    NOUN,anim,masc plur,accs
    ЕЖАМИ   NOUN,anim,masc plur,ablt
    ЕЖАХ    NOUN,anim,masc plur,loct

Сначала указывается номер леммы, затем перечисляются формы слова и
соответствующая им грам. информация. Первая форма считается "нормальной".
В словаре около 400тыс. лемм и 5млн отдельных слов.

Если просто загрузить все слова и их грам. информацию в питоний list,
то это займет примерно 2Гб оперативной памяти. Кроме того, эта форма
неудобна для быстрого выполнения операций по анализу и склонению слов.


Упаковка грам. информации
-------------------------

Очевидно, что набор тегов для слова (``NOUN,anim,masc sing,nomn``)
будет повторяться, и хранить строку целиком для всех 5млн слов накладно.
В pymorphy2 все возможные наборы тегов хранятся в массиве; для каждого слова
указывается только номер набора тегов.

Пример::

    1
    ЁЖ      1
    ЕЖА     2
    ЕЖУ     3
    ЕЖА     4
    ЕЖОМ    5
    ЕЖЕ     6
    ЕЖИ     7
    ЕЖЕЙ    8
    ЕЖАМ    9
    ЕЖЕЙ    10
    ЕЖАМИ   11
    ЕЖАХ    12

Выделение парадигм
------------------

Изначально в словаре из OpenCorpora_ нет понятия "парадигмы" слова.
Парадигма - это таблица форм какого-либо слова, образец для склонения
или спряжения. В pymorphy2 парадигмы необходимы по 2 причинам:

1. многие слова формируются схожим образом, и выделение парадигм
   позволяет снизить потребление оперативной памяти;
2. для того, чтоб склонять неизвестные слова, нужны образцы для склонения.

Пример исходной леммы::

    375080
    ЧЕЛОВЕКОЛЮБИВ   100
    ЧЕЛОВЕКОЛЮБИВА  102
    ЧЕЛОВЕКОЛЮБИВО  105
    ЧЕЛОВЕКОЛЮБИВЫ  110

Парадигма (пусть будет номер 12345)::

    ""      100
    "А"     102
    "О"     105
    "Ы"     110

Вся лемма при этом "сворачивается" в "стем" и номер парадигмы::

    "ЧЕЛОВЕКОЛЮБИ" 12345

.. note::

    Для одного "стема" может быть несколько допустимых парадигм.

Прилагательные на ПО-
^^^^^^^^^^^^^^^^^^^^^

В словарях у большинства сравнительных прилагательных есть формы на ПО-::

    375081
    ЧЕЛОВЕКОЛЮБИВЕЕ COMP,Qual V-ej
    ПОЧЕЛОВЕКОЛЮБИВЕЕ       COMP,Qual Cmp2
    ПОЧЕЛОВЕКОЛЮБИВЕЙ       COMP,Qual Cmp2,V-ej

Можно заметить, что в этом случае форма слова определяется не только тем,
как слово заканчивается, но и тем, как слово начинается. Алгоритм с разбиением
на "стем" и "окончание" приведет к тому, что все слово целиком будет считаться
окончанием, а => каждое сравнительное прилагательное породит еще одну
парадигму. Это увеличивает общее количество парадигм в несколько раз и делает
невозможным склонение несловарных сравнительных прилагательных, поэтому
в pymorphy2 парадигма определяется как "окончание", "номер грам. информации"
и "префикс".

Пример парадигмы для "ЧЕЛОВЕКОЛЮБИВ"::

    ""      100     ""
    "А"     102     ""
    "О"     105     ""
    "Ы"     110     ""

Пример парадигмы для "ЧЕЛОВЕКОЛЮБИВЕЕ"::

    ""      555     ""
    ""      556     "ПО"
    ""      557     "ПО"

.. note::

    Сейчас обрабатывается единственный префикс - "ПО". В словарях, похоже,
    нет других префиксов, присущих только отдельным формам слова в пределах
    одной леммы.

Упаковка "стемов"
-----------------

"Стемы" - строки, основы лемм. Для их хранения используется структура данных
trie_ (с использованием библиотеки datrie_), что позволяет снизить
потребление оперативной памяти (т.к. некоторые общие части слов не дублируются)
и повысить скорость работы (т.к. в trie можно некоторые операции - например,
поиск всех префиксов данной строки - можно выполнять значительно быстрее,
чем в хэш-таблице).

.. _trie: http://en.wikipedia.org/wiki/Trie
.. _datrie: https://github.com/kmike/datrie

Ключами в trie являются стемы (перевернутые), значениями - список с номерами
допустимых парадигм.

Упаковка tuple/list/set
-----------------------

Для каждого стема требуется хранить множество id парадигм; обычно это
множества из небольшого числа int-элементов. В питоне накладные расходы на
set() довольно велики::

    >>> import sys
    >>> sys.getsizeof({})
    280

Если для каждого стема создать даже по одному пустому экземпляру set,
это уже займет порядка 80М памяти. Поэтому set() не используется;
сначала я заменил их на tuple с отсортированными элементами. В таких tuple
можно искать пересечения за O(N+M) через однопроходный алгоритм,
аналогичный сортировке слиянием, или за O(N*log(M)) через двоичный поиск.

Но накладные расходы на создание сотен тысяч tuple с числами тоже велики,
поэтому в pymorphy 2 они упаковываются в одномерный массив чисел
(``array.array``).

Пусть у нас есть такая структура::

    (
        (10, 20, 30),       # 0й элемент
        (20, 40),           # 1й элемент
    )

Она упакуется в такой массив::

    array.array([3, 10, 20, 30, 2, 20, 40])

Сначала указывается длина данных, затем идет сами данные, потом опять длина
и опять данные, и т.д. Для доступа везде вместо старых индексов
(0й элемент, 1й элемент) используются новые: 0й элемент, 4й элемент.
Чтоб получить исходные цифры, нужно залезть в массив по новому индексу,
получить длину N, и взять следующие N элементов.

Итоговый формат данных
----------------------

Таблица с грам. информацией
^^^^^^^^^^^^^^^^^^^^^^^^^^^

::

    ['tag1', 'tag2', ...]

``tag<N>`` - набор грам. тегов, например ``NOUN,anim,masc sing,nomn``.

Этот массив занимает где-то 0.5M памяти.

Парадигмы
^^^^^^^^^

::

    [
        (
            (suffix1, tag_index1, prefix1),
            (suffix2, tag_index2, prefix2),
            ...
        ),
        (
            ...
    ]


``suffix<N>`` и ``prefix<N>`` - это строки с окончанием и префиксом
(например, ``"ЫЙ"`` и ``""``); ``tag_index<N>`` - индекс в таблице
с грам. информацией.

Парадигмы занимают примерно 7-8M памяти.

.. note::

    tuple в парадигмах сейчас не упакованы в линейные структуры;
    упаковка должна уменьшить потребление памяти примерно на 3M.


Стемы
^^^^^

Стемы хранятся в 2 структурах:

* ``array.array`` с упакованными множествами номеров возможных парадигм
  для данного стема::

       [length0, para_id0, para_id1, ..., length1, para_id0, para_id1, ...]

* и trie с ключами-строками и значениями-индексами в массиве значений::

       datrie.BaseTrie(
           'stem1': index1,
           'stem2': index2,
           ...
       )

"Окончания"
^^^^^^^^^^^

Для каждого "окончания" хранится, в каких парадигмах на каких позициях
оно встречается. Эта информация требуется для быстрого поиска нужного слова
"с конца". Для этого используются 3 структуры:

* ``array.array`` с упакованными множествами номеров возможных парадигм
  для данного окончания::

       [length0, para_id0, para_id1, ..., length1, para_id0, para_id1, ...]

  В отличие от аналогичного множества для стемов, номера парадигм могут
  повторяться в пределах окончания.

* ``array.array`` с упакованными множествами индексов в пределах парадигмы::

       [length0, index0, index1, ..., length1, index0, index1, ...]

  Этот массив работает "вместе" с предыдущим, каждому элементу отсюда
  соответствует элемент оттуда - совместно они предоставляют информацию
  о возможных номерах форм в парадигме для всех окончаний.

* trie с ключами-строками и значениями-индексами::

       datrie.BaseTrie(
           'suff1': index1,
           'suff2': index2,
           ...
       )

  По индексу ``index<N>`` можно из предудыщих 2х массивов получить наборы
  форм для данного окончания.

.. note::

    Длины хранятся 2 раза. Может, это можно как-то улучшить?

Характеристики
--------------

После применения описанных выше методов в pymorphy2 словарь
OpenCorpora занимает около 28M оперативной памяти и позволяет проводить
анализ слов (по предварительным тестам; pymorphy2 еще не готов и
скоростные характеристики могут измениться в обе стороны) со
скоростью 20-60 тыс. слов/сек. Для сравнения:

* в mystem_ словарь + код занимает около 3M оперативной памяти,
  скорость > 100тыс. слов/сек;
* в lemmatizer из aot.ru словарь занимает 9M памяти (судя по данным
  `отсюда <http://www.aot.ru/docs/sokirko/Dialog2004.htm>`_),
  скорость > 200тыс слов/сек.;
* в варианте морф. анализатора на конечных автоматах с питоновской оберткой
  к openfst (http://habrahabr.ru/post/109736/) сообщается, что словарь
  занимал 35/3 = 11M после сжатия, скорость порядка 2 тыс слов/сек
  без оптимизаций;
* написанный на питоне вариант морф. анализатора на конечных автоматах
  (автор - Konstantin Selivanov) требовал порядка 300M памяти, скорость порядка
  2 тыс. слов/сек;
* в `pymorphy 0.5.6`_ полностью загруженный в память словарь
  (этот вариант там не документирован) занимает порядка 300M,
  скорость порядка 1-2тыс слов/сек.

Открытые вопросы:

* достаточно ли хороша используемая реализация trie (datrie_) по
  части потребления памяти?
* не лучше ли в trie хранить не стемы, а слова целиком?
* достаточно ли хороша структура данных trie, или нужно использовать DAWG
  или специализированный конечный автомат?

  .. note::

      Тут стоит заметить, что trie можно рассматривать как неминимизированный
      конечный автомат; конкретные действия по разбору слова, которые
      нужно выполнить компьютеру при использовании автоматного подхода,
      очень похожи.

* можно ли обеспечить установку всего этого хозяйства без компилятора С?

.. _mystem: http://company.yandex.ru/technologies/mystem/
.. _pymorphy 0.5.6: http://pymorphy.readthedocs.org/en/v0.5.6/index.html