.. _dictionary:

Словари
=======

В pymorphy2 используются словари из проекта OpenCorpora_,
специальным образом обработанные для быстрых выборок.

.. _OpenCorpora: http://opencorpora.org

Упаковка словаря
----------------

Исходный словарь из OpenCorpora_ представляет собой текстовый файл,
в котором слова объединены в "леммы" следующим образом::

    1
    ЁЖ      NOUN,anim,masc sing,nomn
    ЕЖА     NOUN,anim,masc sing,gent
    ЕЖУ     NOUN,anim,masc sing,datv
    ЕЖА     NOUN,anim,masc sing,accs
    ЕЖОМ    NOUN,anim,masc sing,ablt
    ЕЖЕ     NOUN,anim,masc sing,loct
    ЕЖИ     NOUN,anim,masc plur,nomn
    ЕЖЕЙ    NOUN,anim,masc plur,gent
    ЕЖАМ    NOUN,anim,masc plur,datv
    ЕЖЕЙ    NOUN,anim,masc plur,accs
    ЕЖАМИ   NOUN,anim,masc plur,ablt
    ЕЖАХ    NOUN,anim,masc plur,loct

Сначала указывается номер леммы, затем перечисляются формы слова и
соответствующая им грам. информация. Первая форма считается "нормальной".
В словаре около 400тыс. лемм и 5млн отдельных слов.

Если просто загрузить все слова и их грам. информацию в питоний list,
то это займет примерно 2Гб оперативной памяти. Кроме того, эта форма
неудобна для быстрого выполнения операций по анализу и склонению слов.


Упаковка грам. информации
-------------------------

Очевидно, что набор тегов для слова (``NOUN,anim,masc sing,nomn``)
будет повторяться, и хранить строку целиком для всех 5млн слов накладно.
В pymorphy2 все возможные наборы тегов хранятся в массиве; для каждого слова
указывается только номер набора тегов.

Пример::

    1
    ЁЖ      1
    ЕЖА     2
    ЕЖУ     3
    ЕЖА     4
    ЕЖОМ    5
    ЕЖЕ     6
    ЕЖИ     7
    ЕЖЕЙ    8
    ЕЖАМ    9
    ЕЖЕЙ    10
    ЕЖАМИ   11
    ЕЖАХ    12

Упаковка слов
-------------

Для хранения данных о словах используется граф (Directed acyclic word graph,
`wiki <http://en.wikipedia.org/wiki/Directed_acyclic_word_graph>`__)
с использованием библиотеки DAWG_), что позволяет снизить
потребление оперативной памяти (т.к. общие части слов не дублируются)
и повысить скорость работы (т.к. в DAWG можно быстро выполнять не только
точный поиск слова, но и другие операции - поиск по префиксу, например).

В DAWG помещаются строки вида

    <СЛОВО> <разделитель> <НОМЕР ПАРАДИГМЫ> <ИНДЕКС В ПАРАДИГМЕ>

Для получения всех возможных вариантов разбора слов достаточно найти
все ключи, начинающиеся с ``<СЛОВО> <разделитель>``.

.. _DAWG: https://github.com/kmike/DAWG

Парадигмы
---------

Изначально в словаре из OpenCorpora_ нет понятия "парадигмы" слова.
Парадигма - это таблица форм какого-либо слова, образец для склонения
или спряжения.

В pymorphy2 выделенные явным образом парадигмы слов необходимы для того,
чтоб склонять неизвестные слова - т.к. при этом нужны образцы для склонения.

.. note::

    Для других операций явно выделенные парадигмы тоже могут быть удобными,
    хотя все кроме склонения неизвестных слов можно было бы проводить
    и без явно выделенных парадигм.

Пример исходной леммы::

    375080
    ЧЕЛОВЕКОЛЮБИВ   100
    ЧЕЛОВЕКОЛЮБИВА  102
    ЧЕЛОВЕКОЛЮБИВО  105
    ЧЕЛОВЕКОЛЮБИВЫ  110

У слов есть неизменяемое начало ("стем") и изменяемое
"окончание". Можно было бы выделить парадигму вот так::

    ""      100
    "А"     102
    "О"     105
    "Ы"     110

Этот способ неоптимален, т.к. в словарях OpenCorpora_ у большинства
сравнительных прилагательных есть формы на ПО-::

    375081
    ЧЕЛОВЕКОЛЮБИВЕЕ         COMP,Qual V-ej
    ПОЧЕЛОВЕКОЛЮБИВЕЕ       COMP,Qual Cmp2
    ПОЧЕЛОВЕКОЛЮБИВЕЙ       COMP,Qual Cmp2,V-ej

В этом случае форма слова определяется не только тем, как слово
заканчивается, но и тем, как слово начинается. Если при построении
парадигм учитывать только "стем" и "окончание", то все слово целиком
будет считаться окончанием, а значит каждое сравнительное прилагательное
породит еще одну парадигму. Это увеличит общее количество парадигм в
несколько раз и сделает невозможным склонение несловарных
сравнительных прилагательных, поэтому в pymorphy2 парадигма
определяется как "окончание", "номер грам. информации" и "префикс".

Пример парадигмы для "ЧЕЛОВЕКОЛЮБИВ"::

    ""      100     ""
    "А"     102     ""
    "О"     105     ""
    "Ы"     110     ""

Пример парадигмы для "ЧЕЛОВЕКОЛЮБИВЕЕ"::

    ""      555     ""
    ""      556     "ПО"
    ""      557     "ПО"

.. note::

    Сейчас обрабатывается единственный префикс - "ПО". В словарях, похоже,
    нет других префиксов, присущих только отдельным формам слова в пределах
    одной леммы.


Итоговый формат данных
----------------------

Таблица с грам. информацией
^^^^^^^^^^^^^^^^^^^^^^^^^^^

::

    ['tag1', 'tag2', ...]

``tag<N>`` - набор грам. тегов, например ``NOUN,anim,masc sing,nomn``.

Этот массив занимает где-то 0.5M памяти.

Парадигмы
^^^^^^^^^

::

    [
        (
            (suffix1, tag_index1, prefix1),
            (suffix2, tag_index2, prefix2),
            ...
        ),
        (
            ...
    ]


``suffix<N>`` и ``prefix<N>`` - это строки с окончанием и префиксом
(например, ``"ЫЙ"`` и ``""``); ``tag_index<N>`` - индекс в таблице
с грам. информацией.

Парадигмы занимают примерно 7-8M памяти.

.. note::

    tuple в парадигмах сейчас не упакованы в линейные структуры
    (накладные расходы на создание tuple велики); упаковка должна
    уменьшить потребление памяти примерно на 3M.


Слова
^^^^^

Все слова хранятся в ``dawg.RecordDAWG``::

       dawg.RecordDAWG(
           'word1': (para_id1, para_index1),
           'word1': (para_id2, para_index2),
           'word2': (para_id1, para_index1),
           ...
       )

В DAWG эти слова занимают примерно 5M памяти.

Характеристики
--------------

После применения описанных выше методов в pymorphy2 словарь
OpenCorpora занимает около 13Мб оперативной памяти и позволяет проводить
анализ слов (по предварительным тестам; pymorphy2 еще не готов и
скоростные характеристики могут измениться в обе стороны) со
скоростью > 150 тыс слов/сек. Для сравнения:

* в mystem_ словарь + код занимает около 3Мб оперативной памяти,
  скорость > 100тыс. слов/сек;
* в lemmatizer из aot.ru словарь занимает 9Мб памяти (судя по данным
  `отсюда <http://www.aot.ru/docs/sokirko/Dialog2004.htm>`_),
  скорость > 200тыс слов/сек.;
* в варианте морф. анализатора на конечных автоматах с питоновской оберткой
  к openfst (http://habrahabr.ru/post/109736/) сообщается, что словарь
  занимал 35/3 = 11Мб после сжатия, скорость порядка 2 тыс слов/сек
  без оптимизаций;
* написанный на питоне вариант морф. анализатора на конечных автоматах
  (автор - Konstantin Selivanov) требовал порядка 300Мб памяти, скорость порядка
  2 тыс. слов/сек;
* в `pymorphy 0.5.6`_ полностью загруженный в память словарь
  (этот вариант там не документирован) занимает порядка 300Мб,
  скорость порядка 1-2тыс слов/сек.
* MAnalyzer_ v0.1 (основанный на алгоритмах из pymorphy1, но написанный на C++
  и с использованием dawg) говорят, что скорость разбора 900тыс слов/сек при
  потреблении памяти 40Мб;
* в :ref:`первом варианте <2trie>` формата словарей pymorphy2
  (от которого я отказался) получалась скорость 20-60тыс слов/сек
  при 30M памяти или 2-5 тыс слов/сек при 5Мб памяти.

Цели обогнать C/C++ реализации у pymorphy2 нет; цель - скорость
базового разбора должна быть достаточной для того, чтоб "продвинутые"
операции работали быстро. Мне кажется, 100 тыс. слов/сек или 300 тыс.
слов/сек - это не очень важно, т.к. накладные расходы в реальных задачах
все равно, скорее всего, "съедят" эту разницу (особенно при использовании
из питоньего кода).

.. _mystem: http://company.yandex.ru/technologies/mystem/
.. _pymorphy 0.5.6: http://pymorphy.readthedocs.org/en/v0.5.6/index.html
.. _MAnalyzer: https://github.com/Melkogotto/MAnalyzer